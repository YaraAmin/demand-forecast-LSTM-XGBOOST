{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import division\nfrom datetime import datetime, timedelta,date\nfrom datetime import datetime, timedelta,date\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#import Keras\nimport keras\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam \nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import np_utils\nfrom keras.layers import LSTM\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n#import Keras\nimport keras\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam \nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import np_utils\nfrom keras.layers import LSTM\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_sales =pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/train.csv')\ndf_sales ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert date field from string to datetime\ndf_sales['date'] = pd.to_datetime(df_sales['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#represent month in date field as its first day\ndf_sales['date'] = df_sales['date'].dt.year.astype('str') + '-' + df_sales['date'].dt.month.astype('str') + '-01'\ndf_sales['date'] = pd.to_datetime(df_sales['date'])\n#groupby date and sum the sales\ndf_sales = df_sales.groupby('date').sales.sum().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Transofrmation"},{"metadata":{},"cell_type":"markdown","source":"To model our forecast easier and more accurate, we will do the transformations below:\n- We will convert the data to stationary if it is not\n- Converting from time series to supervised for having the feature set of our LSTM model\n- Scale the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=df_sales.groupby([\"date\"])[\"sales\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the company')\nplt.xlabel('date')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It's not stationary**"},{"metadata":{},"cell_type":"markdown","source":"Obviously, it is not stationary and has an increasing trend over the months. One method is to get the difference in sales compared to the previous month and build the model on it"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a new dataframe to model the difference\ndf_diff = df_sales.copy()\n#add previous sales to the next row\ndf_diff['prev_sales'] = df_diff['sales'].shift(1)\n#drop the null values and calculate the difference\ndf_diff = df_diff.dropna()\ndf_diff['diff'] = (df_diff['sales'] - df_diff['prev_sales'])\ndf_diff.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=df_diff.groupby([\"date\"])[\"diff\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the company')\nplt.xlabel('date')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perfect! Now we can start building our feature set. We need to use previous monthly sales data to forecast the next ones. The look-back period may vary for every model. Ours will be 12 for this example."},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dataframe for transformation from time series to supervised\ndf_supervised = df_diff.drop(['prev_sales'],axis=1)\n#adding lags\nfor inc in range(1,13):\n    field_name = 'lag_' + str(inc)\n    df_supervised[field_name] = df_supervised['diff'].shift(inc)\n#drop null values\ndf_supervised = df_supervised.dropna().reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_supervised","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# split our data into train and test sets. As the test set, we have selected the last 6 monthsâ€™ sales."},{"metadata":{"trusted":true},"cell_type":"code","source":"#import MinMaxScaler and create a new dataframe for LSTM model\nfrom sklearn.preprocessing import MinMaxScaler\ndf_model = df_supervised.drop(['sales','date'],axis=1)\n#split train and test set\ntrain_set, test_set = df_model[0:-6].values, df_model[-6:].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scale Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#apply Min Max Scaler\nscaler = MinMaxScaler(feature_range=(-1, 1))\nscaler = scaler.fit(train_set)\n# reshape training set\ntrain_set = train_set.reshape(train_set.shape[0], train_set.shape[1])\ntrain_set_scaled = scaler.transform(train_set)\n# reshape test set\ntest_set = test_set.reshape(test_set.shape[0], test_set.shape[1])\ntest_set_scaled = scaler.transform(test_set)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{},"cell_type":"markdown","source":"## LSTM model"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1]\nX_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\nX_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1]\nX_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(4, batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), stateful=True))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(X_train, y_train, nb_epoch=100, batch_size=1, verbose=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test,batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### check accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"#reshape y_pred\ny_pred = y_pred.reshape(y_pred.shape[0], 1, y_pred.shape[1])\n#rebuild test set for inverse transform\npred_test_set = []\nfor index in range(0,len(y_pred)):\n    pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))\n#reshape pred_test_set\npred_test_set = np.array(pred_test_set)\npred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])\n#inverse transform\npred_test_set_inverted = scaler.inverse_transform(pred_test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dataframe that shows the predicted sales\nresult_list = []\nsales_dates = list(df_sales[-7:].date)\nact_sales = list(df_sales[-7:].sales)\nfor index in range(0,len(pred_test_set_inverted)):\n    result_dict = {}\n    result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_sales[index])\n    result_dict['date'] = sales_dates[index+1]\n    result_list.append(result_dict)\ndf_result = pd.DataFrame(result_list)\n#for multistep prediction, replace act_sales with the predicted sales","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=df_result.groupby([\"date\"])[\"pred_value\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the company')\nplt.xlabel('date')\nplt.ylabel('pred_value')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBOOST"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost.sklearn import XGBRegressor\n\nX_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1]\nX_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1]\n\nmodel=XGBRegressor( n_estimators=100, \n                                    learning_rate=0.2, \n                                    objective='reg:squarederror')\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_pred = y_pred.reshape(y_pred.shape[0], 1, 1)\n# X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n\n#rebuild test set for inverse transform\npred_test_set = []\nfor index in range(0,len(y_pred)):\n    pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))\n\n#reshape pred_test_set\npred_test_set = np.array(pred_test_set)\npred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])\n\n#inverse transform\npred_test_set_inverted = scaler.inverse_transform(pred_test_set)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_list = []\nsales_dates = list(df_diff[-13:].date)\nact_sales = list(df_diff[-13:].sales)\n\nfor index in range(0,len(pred_test_set_inverted)):\n    result_dict = {}\n    result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_sales[index])\n    result_dict['date'] = sales_dates[index+1]\n    result_list.append(result_dict)\n\ndf_result = pd.DataFrame(result_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=df_result.groupby([\"date\"])[\"pred_value\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the company')\nplt.xlabel('date')\nplt.ylabel('pred_value')\nplt.plot(ts);","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}